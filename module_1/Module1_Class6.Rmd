---
title: "Class 1-6: Discussion of propensity score results"
author: "Health Data Analysis Practicum (AS.280.347)"
date: "February 9, 2026"
output: 
  html_document:
    toc: true
    toc_float: 
      toc_collapsed: true
    toc_depth: 3
    number_sections: false
    keep_md: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, error = TRUE)
```

## Preliminaries

First load the packages that we will be using in this document:
```{r libraries}
library(tidyverse)  # core group of tidyverse packages
library(kableExtra)  # to make nice tables
library(broom)  # for tidy model summaries
library(gtsummary) # to create nice summary tables
```

## Module 1: Smoking and the risk of disease

Questions of interest:

* **Question 1.1: ** How does the risk of disease compare for smokers and otherwise similar non-smokers?

<center>
![](Q1_dag.png){width=500px}
</center>

* **Queston 1.2: ** Does the contribution of smoking to the risk of disease vary by sex or socio-economic status (SES)?

<center>
![](Q2_dag.png){width=500px}
</center>

To address each question we want:

* A data display (graph or table)
* A statistical analysis (with interprepration)

We will answer these questions using data from the National Medical Expenditures Survey (NMES)

## Review of propensity scores and how they alleviate confounding

> There is **confounding** in the effect of a treatment $Z$ (e.g. smoking) on an outcome variable $Y$ (e.g. disease status) if we fail to compare **otherwise similar** units and as a result attribute to $Z$ what is **actually caused by factors $X$** that differ between the $Z=0$ and $Z=1$ observations.

We often display this confounding using a directed acyclic graph (DAG):
![Confounding DAG](confounding_dag.png)

Propensity scores allow us to break the link between our confounders and our *treatment*, removing the first connection in this DAG. Within a propensity score group, there is no association between the counfounding variables and the treatment, and therefore confounding has been controlled.

```{r recoding, echo = FALSE}
nmes_data <- read_csv("module_1/nmesUNPROC.csv")

nmes_data <- nmes_data %>%
  mutate(eversmk = factor(eversmk, levels = c("0", "1"), labels = c("Never smoker", "Ever smoker")),
         lc5 = factor(lc5, levels = c("0", "1"), labels = c("No LC", "LC")),
         chd5 = factor(chd5, levels = c("0", "1"), labels = c("No CHD", "CHD")),
         female = factor(female, levels= c("0", "1"), labels = c("Male", "Female")),
         current = factor(current, levels= c("0", "1"), labels = c("Not current smoker", "Current smoker")),
         former = factor(former, levels= c("0", "1"), labels = c("Not former smoker", "Former smoker")),
         beltuse = factor(beltuse, levels= c("1", "2", "3"), labels = c("Rare", "Some", "Almost always")),
         educate = factor(educate, levels= c("1", "2", "3", "4"), labels = c("College grad", "Some college", "HS grad", "Other")),
         marital = factor(marital, levels= c("1", "2", "3", "4", "5"), labels = c("Married", "Widowed", "Divorced", "Separated", "Never married")),
         poor = factor(poor, levels= c("0", "1"), labels = c("Not poor", "Poor"))
         )

nmes_data <- nmes_data %>%
  mutate(disease = factor(lc5 == "LC" | chd5 == "CHD", 
                          levels=c(FALSE,TRUE), 
                          labels=c("No MSCD", "MSCD")))

```

```{r propmodel}
# fit propensity score model
prop_model_2 <- glm(eversmk ~ age + female + marital + educate, family = binomial(link="logit"), data=nmes_data, na.action = na.exclude)

# calculate propensity scores:
nmes_data <- nmes_data %>%
  mutate(ps_2 = predict(prop_model_2, type = "response"))

# calculate propensity score quintiles:
ps_quintiles_2 <- quantile(nmes_data$ps_2, probs=c(0, 0.2, 0.4, 0.6, 0.8, 1), na.rm=TRUE)  # need na.rm=TRUE to deal with missing values

nmes_data <- nmes_data %>%
  mutate(ps_strata_2 = cut(ps_2, breaks=ps_quintiles_2, include.lowest=TRUE))


```

Before stratifying by propensity score groups, we can see clear associations between the counfounders and the treatment:
```{r summarytab}
nmes_data %>%
  tbl_summary(by = eversmk, 
              include = c(age, female, marital, educate))
```

Are the ever smokers and never smokers "similar"?  How are they different? How can these differences cause problems when we compare disease risk between ever smokers and never smokers?

Now, instead, let's compare ever smokers and never smokers just among the **lowest propensity score quintile**:
```{r summarytabps1}
nmes_data %>%
  filter(ps_strata_2 == "[0.18,0.345]") %>%
  tbl_summary(by = eversmk, 
              include = c(age, female, marital, educate))
```

Here, we can see that the association between our confounders and our treatment (how the distribution of the counfounders varies comparing never-smokers to ever-smokers) is strongly attenuated.

This is true within any of the propensity score strata.

For example, among the **fifth propensity score quintile**:
```{r summarytabps5}
nmes_data %>%
  filter(ps_strata_2 == "(0.659,0.858]") %>%
  tbl_summary(by = eversmk, 
              include = c(age, female, marital, educate))
```

In general, within a propensity score quintile group, the distribution of confounding variables is balanced between the ever and never smoker groups.  So when we compare ever smokers to never smokers within one of these groups, we can say the ever smokers are similar to the never smokers with respect to these variables, i.e., there is no association between the counfounders and the *treatment* (smoking).

This idea is similar to that of a randomized controlled trial, where we randomly assign participants to treatment groups and the randomization assures that all characteristics are balanced between the treatment groups.  Here we are constructing those balanced groups through the use of propensity scores.

Hopefully this helps clarify exactly how propensity scores work to alleviate confounding.


## Discussion of propensity scores verses logistic regression for Question 1-1

In your small groups, take 15 minutes to discuss the results of your propensity score analysis and multivariable logistic regression to answer Question 1.1.  Below are a few of the student comments comparing the two analysis methods. Read them and then through all the posts on the [Piazza thread](https://piazza.com/class/mkfko521yy9w1/post/19){target="_blank"}.

* Based on our analysis, smokers have 1.7051 times the odds of MSCD compared to non-smokers, after controlling for the propensity for smoking due to age and sex (p=0.0002).

* From the multivariable logistic regression (Table 1), results suggest that smokers have 118.9% higher odds of being diagnosed with a major smoking-caused disease compared to never smokers, after controlling for sex, poverty status, and age (p < 0.05). From the table using propensity scores, results suggest that among people with similar age, sex, and poverty status, people who are smokers have  1.544 times the odds of major smoking-causing disease compared to never smokers (95%CI: 1.18-2.03). Comparing results from both analyses, both indicate that after controlling for confounding variables (sex, poverty status, and age), smokers have a higher risk of MSCD than never smokers.  However, accounting for confounding with propensity scores results in a higher risk value than with multivariable regression. The difference is very clear, suggesting there must be one with more certainty. I'm unsure which one would be preferred to answer this question. Still, since propensity scores compare smokers with "otherwise similar" nonsmokers rather than equal, I would say that would be a better way to answer this question.

* The multivariable logistic regression shows that when age, sex, and economic status has been held constant, the odds of having lung cancer or chronic heart diseases for smokers is 2.2 times that of the non-smokers (p<0.001). The propensity score analysis shows that smokers have 1.58 times the odds of lung cancer or chronic heart diseases compared to non-smokers after controlling for the propensity for smoking due to age, sex, economic status, education level, and bmi (p < 0.001). The odds ratio from the two analysis are quite different. Although they both indicate higher risk of diseases for smokers compared to otherwise similar non-smokers, the odds ratio I get for multivariable regression is higher than the propensity score analysis. This is likely due to the fact that I've included more variable for my propensity score analysis (education status & bmi), which pulls the odds ratio towards null. I think considering the propensity score analysis likely better captured the true relationship between smoking and diseases as I accounted for more confounding variables in this analysis, which better addresses the "otherwise similar" consideration.

* In my analysis, the adjusted logistic regression model estimated an OR of 2.02 for smoking, whereas the propensity score quintile model estimated an OR of 1.67. Since both models adjust for the same covariates but use different strategies, what might explain the reduction in the estimated effect size, and does this suggest one method is providing a less biased estimate in this example?
 

Discuss the following questions:

(1) How do the multivariable logistic regression results change depending on which adjustment variables are included in the model?  Do you think this is a problem?  Do these differences change the answer to Question 1.1?

(2) How do the results from the propensity score analyses compare to those from logistic regression?  Do you think any differences in the results are a problem?  Do these differences change the answer to Question 1.1?

(3) What are some of the pros/cons for each analysis method (logistic regression vs. propensity score analysis)?  In particular, look at the width of the confidence intervals for the estimated odds ratios comparing smokers to non-smokers for the multi-variate logistic regression vs the propensity score models. Which method do you prefer in this case, and why? (To make this comparison, you want to have the variables included in your original multi-variate regression model match those used in your propensity score calculation. If you did not do this, go ahead and do it now so you can make the comparison.)

(4) In the student results, was it always clear which variables were included as adjustment variables in the logistic regression model?  Was is always clear which variables were included as adjustment variables in the propensity score analysis?  If not, what are suggestions for either the table of results or the write-up that could make this clear?

(5) Were they any interpretations of results (for either model) that you found particularly well done?  What were the characteristics of those interpretations?

(6) What are your lingering questions about propensity scores?

## R notes based Assignment 1-3

Just a few notes this week: including numbers from your regression results directly into the text in R Markdown and writing numerate sentences when summarizing your results.  Reminder: you should also feel free to ask questions on Piazza if there is something you would like us to help you learn how to do!

### Recoding the data
```{r recode2}
nmes_data <- read_csv("module_1/nmesUNPROC.csv")

nmes_data <- nmes_data %>%
  mutate(eversmk = factor(eversmk, levels = c("0", "1"), labels = c("Never smoker", "Ever smoker")),
         lc5 = factor(lc5, levels = c("0", "1"), labels = c("No LC", "LC")),
         chd5 = factor(chd5, levels = c("0", "1"), labels = c("No CHD", "CHD")),
         female = factor(female, levels= c("0", "1"), labels = c("Male", "Female")),
         current = factor(current, levels= c("0", "1"), labels = c("Not current smoker", "Current smoker")),
         former = factor(former, levels= c("0", "1"), labels = c("Not former smoker", "Former smoker")),
         beltuse = factor(beltuse, levels= c("1", "2", "3"), labels = c("Rare", "Some", "Almost always")),
         educate = factor(educate, levels= c("1", "2", "3", "4"), labels = c("College grad", "Some college", "HS grad", "Other")),
         marital = factor(marital, levels= c("1", "2", "3", "4", "5"), labels = c("Married", "Widowed", "Divorced", "Separated", "Never married")),
         poor = factor(poor, levels= c("0", "1"), labels = c("Not poor", "Poor"))
         )

nmes_data <- nmes_data %>%
  mutate(disease = factor(lc5 == "LC" | chd5 == "CHD", 
                          levels=c(FALSE,TRUE), 
                          labels=c("No MSCD", "MSCD")))
```

### Please do not include call to `install.packages` in your `.Rmd` file code

When I knit a file with `install.packages` in the code, it halts with an error. Packages only need to be installed once, so you don't want to install them every time the file is knit in any case. This is different from loading the library, which you do need to do each time functions from the package are used.

### Propensity scores with smaller groups

Why does it not really make a difference if you use logistic regression or propensity score groups when you have only two binary variables?

First, we use logistic regression to model the log odds of ever smoking based on female and poor:
```{r propmodel2}
prop_model <- glm(eversmk ~ female + poor, family = binomial(link="logit"), data=nmes_data, na.action = na.exclude)

nmes_data <- nmes_data %>%
  mutate(ps = predict(prop_model, type = "response"))


ggplot(data = nmes_data) +
  geom_jitter(mapping = aes(x=ps, y=disease, color=eversmk), alpha = .4) 
```

Note that propensity score groups are completely determined by the female and poor variables:
```{r propmodel2var}
ggplot(data = nmes_data) +
  geom_jitter(mapping = aes(x=ps, y=disease, color=female, shape = poor), alpha = .4) 

```

If we want to have at least four propensity score groups, this means that we would be splitting people into the exact groups they would be split into by the sex/poverty status variables, not providing any benefit. 


### In-line code (including code in within the text)

In your written interpretations of your regression results, you all refer to values that are also presented in your tables of coefficients or odds ratios.  Instead of copying/pasting or typing these numbers into the text, you can refer directly to the values in your tables within your text.  This is called "in-line" code, and it is done using: tick r.

For example, suppose we created the following table of logistic regression results:
```{r inline1}
my_model <- glm(disease ~ eversmk + age + female, family=binomial(link="logit"), data=nmes_data)

my_model_results <- tidy(my_model, 
                         exponentiate = TRUE,
                         conf.int = TRUE) %>%
  mutate(term = recode(term, 
                  "(Intercept)" = "Intercept", 
                  "eversmkEver smoker" = "Ever smoker", 
                  "age" = "Age (years)",
                  "femaleFemale" = "Female"))



my_model_results
```



And we displayed it nicely in the following table:
```{r inline2}
my_model_results %>%
  filter(term != "Intercept") %>% # remove the row with the intercept
  mutate(conf.int = paste0("(", round(conf.low, 2), ", ", round(conf.high, 2), ")")) %>% # combine the CI terms together into nice format 
  select(Variable = term, `Odds Ratio` = estimate, `p-value` = p.value, `95% Confidence Interval` = conf.int) %>% # select only the columns we want, rearrange columns, and change names
  kable(format = "pipe",
        digits = 3,
        align = c("l", "r", "r", "r"))
```

In the text, we might interpret the results as:

Holding age and sex constant, the odds of having a major smoking-caused disease among smokers are 2.2 times the odds of having a disease for non-smokers.

**If we don't want to type out this number, we could use in-line R code instead:** In our table of results (`my_model_results`), the odds ratio for smoking is stored in the `estimate` column where `term == "Ever smoker"`.  We can access that specific table location with:
```{r inline3}
my_model_results %>% filter(term == "Ever smoker") %>% select(estimate) %>% pull()
```

Here the `pull()` function is used to give a single value rather than return a table.  We can then put this value within our text as `r my_model_results %>% filter(term == "Ever smoker") %>% select(estimate) %>% pull()`.  When the report is knit, the results of this code are inserted into the text.

When inserting numbers into text, `format()` is your friend. It allows you to set the number of digits so you donâ€™t print to a ridiculous degree of accuracy.  We can also add `big.mark = ","` to make numbers easier to read or specify that we do not want to use scientific notation here:
```{r inlineformat}
format(3452345, digits = 2, big.mark = ",")
format(0.12358124331, digits = 2, big.mark = ",")
format(9e-2, digits = 3, scientific = FALSE)
```

So we could re-write our results as:

Holding age and sex constant, the odds of having a major smoking-caused disease among smokers is `r my_model_results %>% filter(term == "Ever smoker") %>% select(estimate) %>% pull() %>% format(digits = 2)` times the odds of having a disease for non-smokers.

### Stating numerate results

When writing up your results, be sure to be numerate!  This means including actual values of odds ratios in your write-up (see above), but also means to include information about the statistical significance as well, with supporting evidence like a confidence interval of p-value.  For example, we could improve our intepretation above in a couple of ways:

Holding age and sex constant, the odds of having a major smoking-caused disease among smokers is `r my_model_results %>% filter(term == "Ever smoker") %>% select(estimate) %>% pull() %>% format(digits = 2)` times the odds of having a disease for non-smokers (p = `r my_model_results %>% filter(term == "Ever smoker") %>% select(p.value) %>% pull() %>% format(digits = 2, scientific = FALSE)`).

OR

Holding age and sex constant, the odds of having a major smoking-caused disease among smokers is `r my_model_results %>% filter(term == "Ever smoker") %>% select(estimate) %>% pull() %>% format(digits = 2)` times the odds of having a disease for non-smokers (95% CI for odds ratio: `r my_model_results %>% filter(term == "Ever smoker") %>% select(conf.low) %>% pull() %>% format(digits = 2)` to `r my_model_results %>% filter(term == "Ever smoker") %>% select(conf.high) %>% pull() %>% format(digits = 2)`).


### Adding figure captions and other graph tips

We can add figure captions to our plots in R Markdown.  This code chunk creates a string that will be used below as a figure caption:
```{r figcapexample1}
figcap.nmes = paste0("Figure 1: Scatter plot of log10 medical expenditures vs age for n=", nrow(nmes_data), " observations")
```

We can then add this figure caption to our code chunk header using the `fig.cap` argument in the code chunk header:
```{r figcapexample2, fig.cap = figcap.nmes}
nmes_data %>%
  mutate(log10exp = log10(totalexp)) %>%
  ggplot(mapping = aes(x = age, y = log10exp)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = "red")
``` 

Note that we can use options like `include = FALSE`, `echo = FALSE`, and `message = FALSE` in our code chunk headers to control what is printed out in the actual report.  So if we just want to include the graph and not the code for either the graph or the caption we could set `include = FALSE` for the caption definition chunk and `echo = FALSE` for the plot chunk.  We can also supress the message about `geom_smooth` by including `message = FALSE` in our chunk for the graph.

Then we **just** get the graph in our report while hiding all the code that went into creating it!

```{r figcapexample3, include = FALSE}
figcap.nmes = paste0("Figure 1: Scatter plot of log10 medical expenditures vs age for n=", nrow(nmes_data), " observations")
```

```{r figcapexample4, fig.cap = figcap.nmes, echo = FALSE, message = FALSE}
nmes_data %>%
  mutate(log10exp = log10(totalexp)) %>%
  ggplot(mapping = aes(x = age, y = log10exp)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = "red")
``` 

## Interpreting propensity score results

Suppose we calculate propensity scores based on **age** and **sex**:
```{r propresinterpret}
# fit propensity score model: trt ~ confounders
prop_model <- glm(eversmk ~ age + female, family = binomial(link="logit"), data=nmes_data, na.action = na.exclude)

# calculate propensity scores:
nmes_data <- nmes_data %>%
  mutate(ps = predict(prop_model, type = "response"))

# calculate propensity score quintiles:
ps_quintiles <- quantile(nmes_data$ps, probs=c(0, 0.2, 0.4, 0.6, 0.8, 1), na.rm=TRUE)

nmes_data <- nmes_data %>%
  mutate(ps_strata = cut(ps, breaks=ps_quintiles, include.lowest=TRUE))

# model log odds of disease from smoking and ps quintiles
model_ps_strata <- glm(disease ~ eversmk + ps_strata, family = binomial(link="logit"), data=nmes_data)
summary(model_ps_strata)

# transform log OR to OR
exp(coef(model_ps_strata))
```

We would interpret the coefficient for `eversmk` as follows.  We *do not* need to interpret the coefficients for the propensity score quintiles because these variables are just there for adjustment purposes and are not the relationship of interest!

<center>
![](PS_interpretation.png){width=600px}
</center>

## Looking ahead to Wednesday: Effect modification

On Wednesday we will finally consider **Question 1.2: ** Does the contribution of smoking to the risk of disease vary by sex or socio-economic status (SES)?

<center>
![](Q2_dag.png){width=500px}

</center>

An **effect modification** (or **interaction**) is present when the relationship between a predictor of interest and the outcome varies by the level (subgroup) of another variable.

For example, if we thought the effect of smoking on disease was different (larger or smaller) for males than it is for females, we would want to consider a model that allows sex to *modify* the relationship between smoking and disease.

### Discussion: How can we investigate whether sex *modifies* the relationship between smoking and disease using a data display?

Let's start with a display similar to what we've already considered for Question 1.1:

```{r effectmodification}
my_table <- nmes_data %>%
  count(female, eversmk, disease) %>%
  group_by(female, eversmk) %>%
  mutate(prop = n/sum(n)) %>%
  filter(disease == "MSCD")

my_table %>%
  ggplot() +
  geom_bar(aes(x = eversmk, y = prop), stat = "identity") + 
  facet_wrap(~ female)
```

What, if anything, does this graph suggest about whether there's a different relationship between smoking and disease for male compared to female individuals?


## Assignment 1.4: Final Module 1 Report

Finalize your report for Module 1 to answer Questions 1.1 and 1.2.

* For each question, you should have a data display and a statistical analysis to address the question.
* For Question 1.1, decide whether you want to use a multivariable logistic regression model or a propensity score analysis to answer the question.
* For Question 1.2, choose *either* sex or a variable related to SES and create a graph to investigate whether there is effect modification present.
* For Question 1.2, choose *either* sex or a variable related to SES and include an interaction in either your multivariable logistic regression or your propensity score analysis to formally test whether effect modification exists. 


You should also do the following:

* Provide a caption for your data displays.
* Write up your results in a few paragraphs to answer both questions.  In your write-up, you should refer to your data displays and your analysis results.  Be numerate!
* Here's a great resource for tables/figures for scientific papers:
[http://abacus.bates.edu/~ganderso/biology/resources/writing/HTWtablefigs.html](http://abacus.bates.edu/~ganderso/biology/resources/writing/HTWtablefigs.html)

Submit your data display in R Markdown through Github by Monday (February 17, 2025) at midnight.

* You may work together on this assignment, but you must submit your own assignment; please credit in your assignment anyone with whom you collaborated.

* Next week in class we will start Module 2!